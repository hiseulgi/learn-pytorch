{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and import data from open datasets\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Datasets into DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N merujuk pada jumlah sampel dalam suatu batch.\n",
    "- C merujuk pada jumlah saluran atau channel dalam suatu citra.\n",
    "- H merujuk pada tinggi atau jumlah baris piksel dalam citra.\n",
    "- W merujuk pada lebar atau jumlah kolom piksel dalam citra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (feed forward to it in batches), and backpropagates the prediction error to adjust the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainer function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 250 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing function to check model performance\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.295694  [   64/60000]\n",
      "loss: 2.278235  [16064/60000]\n",
      "loss: 2.229173  [32064/60000]\n",
      "loss: 2.198641  [48064/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 2.169880 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.166792  [   64/60000]\n",
      "loss: 2.135132  [16064/60000]\n",
      "loss: 2.030191  [32064/60000]\n",
      "loss: 1.973690  [48064/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.928798 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.946573  [   64/60000]\n",
      "loss: 1.892251  [16064/60000]\n",
      "loss: 1.704799  [32064/60000]\n",
      "loss: 1.593277  [48064/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 1.570178 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.624218  [   64/60000]\n",
      "loss: 1.574833  [16064/60000]\n",
      "loss: 1.388434  [32064/60000]\n",
      "loss: 1.252230  [48064/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.291441 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.360897  [   64/60000]\n",
      "loss: 1.331465  [16064/60000]\n",
      "loss: 1.182955  [32064/60000]\n",
      "loss: 1.030541  [48064/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.115581 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# training process\n",
    "epochs = 5\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to 00-model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models/00-model.pth\")\n",
    "print(\"Saved PyTorch Model State to 00-model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_latest = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"models/00-model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Bag\", Actual: \"Bag\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "data_id = 30\n",
    "x, y = test_data[data_id][0], test_data[data_id][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "    plt.imshow(x.cpu().numpy().squeeze(), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
